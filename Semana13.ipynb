{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Semana13.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8RbiB9j6NNG"
      },
      "source": [
        "Pré processar o arquivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOHLPOkxHw1n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6h3EopV6NNJ"
      },
      "source": [
        "import sys\n",
        "\n",
        "InputFile = \"lots_text.txt\"\n",
        "f = open(InputFile, \"r\", encoding='utf-8')\n",
        "\n",
        "txt = f.read()\n",
        "for t in ((\"alegria\", \"positivo\"), (\"raiva\", \"negativo\"), (\"medo\", \"negativo\"), (\"desgosto\", \"negativo\"), (\"tristeza\", \"negativo\")):\n",
        "    txt = txt.replace(*t)\n",
        "\n",
        "with open(InputFile, 'w', encoding='utf-8') as f:\n",
        "    f.write(txt)                  \n",
        "\n",
        "f.close()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X19ccsJE6NNK"
      },
      "source": [
        "with open(InputFile,\"r+\", encoding='utf-8') as f:\n",
        "    new_f = f.readlines()\n",
        "    f.seek(0)\n",
        "    for line in new_f:\n",
        "        if \"surpresa\" not in line:\n",
        "            f.write(line)\n",
        "    f.truncate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bd30IZe6NNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e48a67-82ca-4c78-932b-4dfd105546f9"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import classification_report\n",
        "from operator import itemgetter, attrgetter\n",
        "import numpy as np\n",
        "import nltk\n",
        "import math\n",
        "nltk.download(['stopwords','rslp','punkt'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdHYh_mQ6NNL"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese') \n",
        "stopwords+= (',','.','(',')','\"',\"'\",'´','`','!','$','%','&','...','-',':',';','?','``','\\'\\'') \n",
        "stopwords+= ('a','e','i','o','u','A','E','I','O','U') \n",
        "\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2-I2ews6NNM"
      },
      "source": [
        "InputFile = \"lots_text.txt\"\n",
        "\n",
        "f = open(InputFile, \"r\", encoding=\"utf-8\")\n",
        "data = []\n",
        "\n",
        "\n",
        "while True:\n",
        "    for line in f:\n",
        "        text = line.split(';')\n",
        "                \n",
        "        tokens = nltk.word_tokenize(text[1]) \n",
        "        tokensLimpo = []\n",
        "        for palavra in tokens:\n",
        "            if (palavra not in stopwords):\n",
        "                tokensLimpo.append(stemmer.stem(palavra)) \n",
        "        instance = (text[0],tokensLimpo)  \n",
        "        data.append(instance)\n",
        "    if line == 'positivo;felipe':\n",
        "        break\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrBRY3zd6NNM"
      },
      "source": [
        "allwords = []\n",
        "for text in data:\n",
        "    for word in text[1]:\n",
        "        if word not in allwords:\n",
        "            allwords.append(word)  \n",
        "            allwords.sort()\n",
        "qtdPalavras = len(allwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwD1nON16NNM"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "for texto in data:\n",
        "    ocorrencias = []\n",
        "    labels.append(texto[0])\n",
        "    \n",
        "    for palavra in allwords:\n",
        "        if palavra in texto[1]:\n",
        "            ocorrencias.append(texto[1].count(palavra))\n",
        "        else:\n",
        "            ocorrencias.append(0)\n",
        "    features.append(ocorrencias)\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5RhInNQ6NNN",
        "outputId": "78059ace-2b73-4088-999e-89581c07a77b"
      },
      "source": [
        "print('----------------------------------------------') \n",
        "print(\"Instâncias 3 classes: \"+str(len(labels)))\n",
        "print(\"Features 3 classes: \"+str(len(features[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------\n",
            "Instâncias 3 classes: 1747\n",
            "Features 3 classes: 6497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfifDSUQ6NNN"
      },
      "source": [
        "def SVM(features, labels, folds):\n",
        "    print('Linear SVM start: ')\n",
        "    clf = svm.SVC(kernel='linear', C=1)\n",
        "    predict = cross_val_predict(clf, features, labels, cv=folds)\n",
        "    cm = confusion_matrix(labels, predict)\n",
        "    print(cm)\n",
        "    print(classification_report(labels, predict, target_names=np.unique(labels)))\n",
        "    print('----------------------------------------------')\n",
        "    return predict, cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn5ZwUA56NNN",
        "outputId": "036b7585-21d8-4a2d-c362-9c972b6d5501"
      },
      "source": [
        "predict = SVM(features, labels, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear SVM start: \n",
            "[[885 113  23]\n",
            " [165 340  36]\n",
            " [ 72  70  43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.79      0.87      0.83      1021\n",
            "      neutro       0.65      0.63      0.64       541\n",
            "    positivo       0.42      0.23      0.30       185\n",
            "\n",
            "    accuracy                           0.73      1747\n",
            "   macro avg       0.62      0.58      0.59      1747\n",
            "weighted avg       0.71      0.73      0.71      1747\n",
            "\n",
            "----------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5FZ8Eg26NNO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}